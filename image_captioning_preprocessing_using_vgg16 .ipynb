{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaVg7s0kWkdO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import progressbar\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.keras.backend.set_session\n",
        "import keras\n",
        "import sys, time, os, warnings \n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from collections import Counter \n",
        "from tensorflow.keras.utils import load_img\n",
        "from nltk.tokenize import word_tokenize\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv(directory):\n",
        "    desc=dict()\n",
        "    text = pd.read_csv(directory, delimiter='|',header=None,names=[\"filename\",\"index\",\"caption\"])\n",
        "    text = text.iloc[1:,:]\n",
        "    df_new = text[text.iloc[:,2].notnull()]\n",
        "    print(df_new.iloc[:5,:])\n",
        "    return df_new  "
      ],
      "metadata": {
        "id": "5oIl-fr9WpuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "p62krIGzWsgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the Datasetfrom Kaggle\n",
        "import opendatasets as od \n",
        "od.download(\"kaggle.com/datasets/srbhshinde/flickr8k-sau\", force=True)"
      ],
      "metadata": {
        "id": "K3YgLjlPWu9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_Flickr_text = \"/content/flickr8k-sau/flickr8k-sau/Flickr_Data/Flickr_TextData/Flickr8k.token.txt\"\n",
        "dir_Flickr_jpg = \"/content/flickr8k-sau/Flickr_Data/Images\"\n",
        "\n",
        "jpgs = os.listdir(dir_Flickr_jpg)\n",
        "print(\"The number of jpg flies in Flicker30k: {}\".format(len(jpgs)))"
      ],
      "metadata": {
        "id": "ah_6ZcN5WxhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(dir_Flickr_text,'r')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "\n",
        "datatxt = []\n",
        "for line in text.split('\\n'):\n",
        "    col = line.split('\\t')\n",
        "    if len(col) == 1:\n",
        "        continue\n",
        "    w = col[0].split(\"#\")\n",
        "    datatxt.append(w + [col[1].lower()])\n",
        "\n",
        "df_txt = pd.DataFrame(datatxt,columns=[\"filename\",\"index\",\"caption\"])\n",
        "\n",
        "\n",
        "uni_filenames = np.unique(df_txt.filename.values)\n",
        "print(\"The number of unique file names : {}\".format(len(uni_filenames)))\n",
        "print(\"The distribution of the number of captions for each image:\")\n",
        "Counter(Counter(df_txt.filename.values).values())"
      ],
      "metadata": {
        "id": "TpyGOJ3uW1qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "npic = 5\n",
        "npix = 224\n",
        "target_size = (npix,npix,3)\n",
        "\n",
        "count = 1\n",
        "fig = plt.figure(figsize=(10,20))\n",
        "for jpgfnm in uni_filenames[:npic]:\n",
        "    filename = dir_Flickr_jpg + '/' + jpgfnm\n",
        "    captions = list(df_txt[\"caption\"].loc[df_txt[\"filename\"]==jpgfnm].values)\n",
        "    image_load = load_img(filename, target_size=target_size)\n",
        "    \n",
        "    ax = fig.add_subplot(npic,2,count,xticks=[],yticks=[])\n",
        "    ax.imshow(image_load)\n",
        "    count += 1\n",
        "    \n",
        "    ax = fig.add_subplot(npic,2,count)\n",
        "    plt.axis('off')\n",
        "    ax.plot()\n",
        "    ax.set_xlim(0,1)\n",
        "    ax.set_ylim(0,len(captions))\n",
        "    for i, caption in enumerate(captions):\n",
        "        ax.text(0,i,caption,fontsize=20)\n",
        "    count += 1\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tqBgvixPXHM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_word(df_txt):\n",
        "    vocabulary = []\n",
        "    for i in range(len(df_txt)):\n",
        "        temp=df_txt.iloc[i,2]\n",
        "        vocabulary.extend(temp.split())\n",
        "    print('Vocabulary Size: %d' % len(set(vocabulary)))\n",
        "    ct = Counter(vocabulary)\n",
        "    dfword = pd.DataFrame({\"word\":list(ct.keys()),\"count\":list(ct.values())})\n",
        "    dfword = dfword.sort_values(\"count\",ascending=False)\n",
        "    dfword = dfword.reset_index()[[\"word\",\"count\"]]\n",
        "    return(dfword)\n",
        "dfword = df_word(df_txt)\n",
        "dfword.head(3)"
      ],
      "metadata": {
        "id": "WCGC1Kw3XKID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topn = 50\n",
        "\n",
        "def plthist(dfsub, title=\"The top 50 most frequently appearing words\"):\n",
        "    plt.figure(figsize=(20,3))\n",
        "    plt.bar(dfsub.index,dfsub[\"count\"])\n",
        "    plt.yticks(fontsize=20)\n",
        "    plt.xticks(dfsub.index,dfsub[\"word\"],rotation=90,fontsize=20)\n",
        "    plt.title(title,fontsize=20)\n",
        "    plt.show()\n",
        "\n",
        "plthist(dfword.iloc[:topn,:],\n",
        "        title=\"The top 50 most frequently appearing words\")\n",
        "plthist(dfword.iloc[-topn:,:],\n",
        "        title=\"The least 50 most frequently appearing words\")"
      ],
      "metadata": {
        "id": "tz2cghTwXSCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def remove_punctuation(text_original):\n",
        "    text_no_punctuation = text_original.translate(str.maketrans('','',string.punctuation))\n",
        "    return(text_no_punctuation)\n",
        "\n",
        "def remove_single_character(text):\n",
        "    text_len_more_than1 = \"\"\n",
        "    for word in text.split():\n",
        "        if len(word) > 1:\n",
        "            text_len_more_than1 += \" \" + word\n",
        "    return(text_len_more_than1)\n",
        "\n",
        "def remove_numeric(text,printTF=False):\n",
        "    text_no_numeric = \"\"\n",
        "    for word in text.split():\n",
        "        isalpha = word.isalpha()\n",
        "        if printTF:\n",
        "            print(\"    {:10} : {:}\".format(word,isalpha))\n",
        "        if isalpha:\n",
        "            text_no_numeric += \" \" + word\n",
        "    return(text_no_numeric)"
      ],
      "metadata": {
        "id": "1bt-vjlkXZuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_clean(text_original):\n",
        "    text = remove_punctuation(text_original)\n",
        "    text = remove_single_character(text)\n",
        "    text = remove_numeric(text)\n",
        "    return(text)\n",
        "\n",
        "with progressbar.ProgressBar(max_value=len(df_txt.caption.values)) as bar:\n",
        "    for i, caption in enumerate(df_txt.caption.values):\n",
        "        newcaption = text_clean(caption)\n",
        "        df_txt[\"caption\"].iloc[i] = newcaption\n",
        "        bar.update(i)\n"
      ],
      "metadata": {
        "id": "kW4rS9wTXiLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plthist(dfword.iloc[:topn,:],\n",
        "        title=\"The top 50 most frequently appearing words\")\n",
        "plthist(dfword.iloc[-topn:,:],\n",
        "        title=\"The least 50 most frequently appearing words\")"
      ],
      "metadata": {
        "id": "IrSEuaO9XlzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import copy\n",
        "def add_start_end_seq_token(captions):\n",
        "    caps = []\n",
        "    for txt in captions:\n",
        "        txt = 'startseq ' + txt + ' endseq'\n",
        "        caps.append(txt)\n",
        "    return(caps)\n",
        "df_txt0 = copy(df_txt)\n",
        "df_txt0[\"caption\"] = add_start_end_seq_token(df_txt[\"caption\"])\n",
        "df_txt0.head(5)\n",
        "del df_txt"
      ],
      "metadata": {
        "id": "V5fpPWJHXoAy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}